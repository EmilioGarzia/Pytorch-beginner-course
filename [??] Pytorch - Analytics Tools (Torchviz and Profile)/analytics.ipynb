{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch beginner course: Analytics tools (Torchviz and Profiler)\n",
    "## Summary\n",
    "\n",
    "- [What is Torchviz?](#what-is-torchivz)\n",
    "- [How to install torchviz](#how-to-install-torchviz)\n",
    "- [How to use torchviz](#how-to-use-torchviz)\n",
    "- [Autograd profiler](#autograd-profiler)\n",
    "- [References](#references)\n",
    "- [Author](#author)\n",
    "\n",
    "## What is Torchviz?\n",
    "\n",
    "In the previous lecture we saw that pytorch can memorize all operations that we can compute on our model or on our tensors, all operations are stored in *graph* called *computational graph* and we can represent this graph using a `torchviz` module, as we can see with this module we can specify some information about the desired computational graph.\n",
    "\n",
    "So the `torchviz` module is the first tool that we will see in this notebook and we will use it to render an image *(or other kind of file)* that represent a computational graph made by our operations.\n",
    "\n",
    "## How to install torchviz\n",
    "\n",
    "To work correctly `torchviz` require another framework called `graphviz` that we can download on web site [Graphviz download](https://graphviz.org/download/).\n",
    "\n",
    "On Unix-Like and macOS system you can install `graphviz` directly from terminal:\n",
    "\n",
    "```bash\n",
    "# Debian distribution\n",
    "sudo apt install graphviz\n",
    "```\n",
    "\n",
    "```bash\n",
    "# macOS terminal\n",
    "brew install graphviz\n",
    "```\n",
    "\n",
    "So after then we install the `graphviz` we can install the `torchviz` module using the `pip` package manager with below command:\n",
    "\n",
    "```bash\n",
    "pip install torchviz\n",
    "```\n",
    "\n",
    "## How to use Torchviz\n",
    "\n",
    "To render an image that represent our computational graph we need to import the `make_dot` function defined in the `torchviz` module, so we proced to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do some operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a tensors\n",
    "x = torch.tensor([1.,6.], requires_grad=True)\n",
    "y = torch.tensor([2.,3.], requires_grad=True) \n",
    "\n",
    "# Compute the first calculation of our model\n",
    "z = (x*2)+(y**3)\n",
    "\n",
    "# apply a reduction on our output tensor z\n",
    "z = z.mean()\n",
    "\n",
    "# invoke the backward method on z\n",
    "z.backward(retain_graph=True)\n",
    "\n",
    "# Here we can provide to call a make_dot method to render an image with our computational graph\n",
    "try:\n",
    "    graph = make_dot(var=z, params={\"x\": x, \"y\": y}, sow_attrs=True)\n",
    "    graph.render(\"graph\", format=\"png\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš : In this case we implement the code into a jupyter notebook, for this reason we have inserted the last two line of the code into a `try-except` construct to avoid the error relative to the executable program named `dot` included into the `graphviz`. When you use `torchviz` in your project you can remove the `try-except` construct.\n",
    "\n",
    "To render a computational graph we used a `make_dot` function with some specified arguments in input:\n",
    "\n",
    "* `var` &rarr; Specify the output node of the computational graph\n",
    "* `params` &rarr; Specify the nodes of our graph *(tensors)*\n",
    "* `show_attrs` &rarr; If `True`, the attributes of the nodes are visibile\n",
    "\n",
    "The other method `render` require two arguments:\n",
    "\n",
    "* *Name of the our output file*\n",
    "* *The format of the output file, that could be `png`, `pdf`, `jpg`, etc.*\n",
    "\n",
    "When you run this code on your environment the code generate a file named `graph.png` that represent the computational graph, the output image produced by our code is showed below:\n",
    "\n",
    "![computational graph](images/graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd profiler\n",
    "\n",
    "`Torchviz` is an external module to analyze our model, but also `torch` have a built-in functions to show some important informations, so in this notebook we will see the `profiler`. The profiler show us the information about the hardware resources consumption during the operations applied on our tensors.\n",
    "\n",
    "As following we have implemented a code that use a profiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             aten::mean        18.18%      20.000us        49.09%      54.000us      54.000us             1  \n",
      "                                              aten::sum        12.73%      14.000us        14.55%      16.000us      16.000us             1  \n",
      "                                       aten::as_strided         1.82%       2.000us         1.82%       2.000us       2.000us             1  \n",
      "                                            aten::fill_         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                             aten::div_         9.09%      10.000us        16.36%      18.000us      18.000us             1  \n",
      "                                               aten::to         0.91%       1.000us         7.27%       8.000us       8.000us             1  \n",
      "                                         aten::_to_copy         3.64%       4.000us         6.36%       7.000us       7.000us             1  \n",
      "                                    aten::empty_strided         0.91%       1.000us         0.91%       1.000us       1.000us             1  \n",
      "                                            aten::copy_         1.82%       2.000us         1.82%       2.000us       2.000us             1  \n",
      "                                        aten::ones_like         2.73%       3.000us         4.55%       5.000us       5.000us             1  \n",
      "                                       aten::empty_like         1.82%       2.000us         1.82%       2.000us       2.000us             1  \n",
      "                                    aten::empty_strided         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                            aten::fill_         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "     autograd::engine::evaluate_function: MeanBackward0         2.73%       3.000us        26.36%      29.000us      29.000us             1  \n",
      "                                          MeanBackward0         5.45%       6.000us        23.64%      26.000us      26.000us             1  \n",
      "                                           aten::expand         5.45%       6.000us         5.45%       6.000us       6.000us             1  \n",
      "                                       aten::as_strided         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                              aten::div         8.18%       9.000us        12.73%      14.000us      14.000us             1  \n",
      "                                               aten::to         0.91%       1.000us         4.55%       5.000us       5.000us             1  \n",
      "                                         aten::_to_copy         1.82%       2.000us         3.64%       4.000us       4.000us             1  \n",
      "                                    aten::empty_strided         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                            aten::copy_         1.82%       2.000us         1.82%       2.000us       2.000us             1  \n",
      "      autograd::engine::evaluate_function: MulBackward0        -5.45%      -6.000us        10.91%      12.000us      12.000us             1  \n",
      "                                           MulBackward0         9.09%      10.000us         9.09%      10.000us      10.000us             1  \n",
      "                                              aten::mul         1.82%       2.000us         7.27%       8.000us       8.000us             1  \n",
      "                                               aten::to         2.73%       3.000us         2.73%       3.000us       3.000us             1  \n",
      "                                         aten::_to_copy         1.82%       2.000us         2.73%       3.000us       3.000us             1  \n",
      "                                    aten::empty_strided         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                            aten::copy_         0.91%       1.000us         0.91%       1.000us       1.000us             1  \n",
      "autograd::engine::evaluate_function: torch::autograd...         1.82%       2.000us         9.09%      10.000us      10.000us             1  \n",
      "                        torch::autograd::AccumulateGrad         4.55%       5.000us         7.27%       8.000us       8.000us             1  \n",
      "                                           aten::detach         0.91%       1.000us         2.73%       3.000us       3.000us             1  \n",
      "                                                 detach         1.82%       2.000us         1.82%       2.000us       2.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 110.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "# Initialize a tensor\n",
    "x = torch.ones(2, requires_grad=True)\n",
    "\n",
    "# define output tensor made by a multiplication by 2\n",
    "z = x*2\n",
    "\n",
    "# Profile the computational graph\n",
    "with profiler.profile() as profiling:\n",
    "    # reduce z and apply backward\n",
    "    z = z.mean()\n",
    "    z.backward()\n",
    "\n",
    "# Print the report of our profiling\n",
    "print(profiling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Pytorch documentation](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "[Torchviz GitHub](https://github.com/szagoruyko/pytorchviz)\n",
    "\n",
    "[Graphviz download page](https://graphviz.org/download/)\n",
    "\n",
    "## Author\n",
    "\n",
    "Emilio Garzia, 2024\n",
    "\n",
    "[Github](https://github.com/EmilioGarzia)\n",
    "\n",
    "[Linkedin](https://www.linkedin.com/in/emilio-garzia-58a934294/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
